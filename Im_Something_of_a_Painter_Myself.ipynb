{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#TF\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Kaggle\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "\n",
        "# general\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import PIL\n",
        "\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-08-08T10:33:56.174317Z",
          "iopub.execute_input": "2022-08-08T10:33:56.174998Z",
          "iopub.status.idle": "2022-08-08T10:34:08.233679Z",
          "shell.execute_reply.started": "2022-08-08T10:33:56.174874Z",
          "shell.execute_reply": "2022-08-08T10:34:08.232447Z"
        },
        "trusted": true,
        "id": "A_l1KozKpF3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GCS_PATH - datasets\n",
        "\n",
        "# if TPU\n",
        "GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\n",
        "\n",
        "# if GPU\n",
        "# GCS_PATH='//kaggle//input//gan-getting-started'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:08.236279Z",
          "iopub.execute_input": "2022-08-08T10:34:08.236631Z",
          "iopub.status.idle": "2022-08-08T10:34:08.619861Z",
          "shell.execute_reply.started": "2022-08-08T10:34:08.236589Z",
          "shell.execute_reply": "2022-08-08T10:34:08.618888Z"
        },
        "trusted": true,
        "id": "o7Cg58kCpF3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data handling**\n",
        "> next we explore some of the data by printing the data details. we define some utilities functions,such as data augmention, prepare the data for training and show some examples."
      ],
      "metadata": {
        "id": "EMmHWHXJpF3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\n",
        "print('Monet TFRecord Files:', len(MONET_FILENAMES))\n",
        "\n",
        "PHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n",
        "print('Photo TFRecord Files:', len(PHOTO_FILENAMES))\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "n_monet_samples = count_data_items(MONET_FILENAMES)\n",
        "n_photo_samples = count_data_items(PHOTO_FILENAMES)\n",
        "\n",
        "# 41 with GEN2 epoch 30 batch 4\n",
        "\n",
        "# DONE      title: GEN3 - BATCH_SIZE=4, EPOCHS_NUM=30\n",
        "# DONE   title: GEN3 - BATCH_SIZE=8, EPOCHS_NUM=30, lambda=10\n",
        "# DONE title: GEN3 - BATCH_SIZE=32, EPOCHS_NUM=50, lambda=1\n",
        "# DONE title: GEN3 - BATCH_SIZE=8, EPOCHS_NUM=30, lambda=3\n",
        "# title: GEN3 - BATCH_SIZE=4, EPOCHS_NUM=30, lambda=12\n",
        "\n",
        "\n",
        "BATCH_SIZE =  4 #16\n",
        "EPOCHS_NUM = 30\n",
        "IMAGE_SIZE = [256, 256]\n",
        "\n",
        "OUTPUT_CHANNELS = 3\n",
        "\n",
        "print(\"Monet TFRecord files: {MONET_LEN}\".format(MONET_LEN=len(MONET_FILENAMES)))\n",
        "print(\"Monet image files: {n_monet_samples}\".format(n_monet_samples=n_monet_samples))\n",
        "\n",
        "print(\"Photo TFRecord files: {PHOTO_LEN}\".format(PHOTO_LEN=len(PHOTO_FILENAMES)))\n",
        "print(\"Photo image files: {n_photo_samples}\".format(n_photo_samples=n_photo_samples))\n",
        "\n",
        "print(\"Batch_size: {BATCH_SIZE}\".format(BATCH_SIZE=BATCH_SIZE))\n",
        "print(\"Epochs number: {EPOCHS_NUM}\".format(EPOCHS_NUM=EPOCHS_NUM))\n",
        "print(\"Image size: {IMAGE_SIZE}\".format(IMAGE_SIZE=IMAGE_SIZE))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:08.621084Z",
          "iopub.execute_input": "2022-08-08T10:34:08.621337Z",
          "iopub.status.idle": "2022-08-08T10:34:08.790366Z",
          "shell.execute_reply.started": "2022-08-08T10:34:08.621302Z",
          "shell.execute_reply": "2022-08-08T10:34:08.789750Z"
        },
        "trusted": true,
        "id": "CcLaTTv8pF3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some utilities\n",
        "\n",
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    tfrecord_format = {\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:08.792153Z",
          "iopub.execute_input": "2022-08-08T10:34:08.792382Z",
          "iopub.status.idle": "2022-08-08T10:34:08.799806Z",
          "shell.execute_reply.started": "2022-08-08T10:34:08.792355Z",
          "shell.execute_reply": "2022-08-08T10:34:08.799148Z"
        },
        "trusted": true,
        "id": "CvLU5pNZpF3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Data Augmention*"
      ],
      "metadata": {
        "id": "sou99DH-pF3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augment(image):\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    if p_crop > .5:\n",
        "        image = tf.image.resize(image, [286, 286])\n",
        "        image = tf.image.random_crop(image, size=[256, 256, 3])\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.resize(image, [300, 300])\n",
        "            image = tf.image.random_crop(image, size=[256, 256, 3])\n",
        "    \n",
        "    if p_rotate > .9:\n",
        "        image = tf.image.rot90(image, k=3)\n",
        "    elif p_rotate > .7:\n",
        "        image = tf.image.rot90(image, k=2)\n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=1)\n",
        "        \n",
        "    if p_spatial > .6:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        if p_spatial > .9:\n",
        "            image = tf.image.transpose(image)\n",
        "    \n",
        "    return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:08.800876Z",
          "iopub.execute_input": "2022-08-08T10:34:08.801077Z",
          "iopub.status.idle": "2022-08-08T10:34:08.814895Z",
          "shell.execute_reply.started": "2022-08-08T10:34:08.801053Z",
          "shell.execute_reply": "2022-08-08T10:34:08.814234Z"
        },
        "trusted": true,
        "id": "P_0DAwnHpF3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Handling functions"
      ],
      "metadata": {
        "id": "j6dYILAepF3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filenames):\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_gan_dataset(monet_files, photo_files, augment=None, repeat=True, shuffle=True, batch_size=1):\n",
        "\n",
        "    monet_ds = load_dataset(monet_files)\n",
        "    photo_ds = load_dataset(photo_files)\n",
        "    \n",
        "    monet_ds = monet_ds.map(augment, num_parallel_calls=AUTO)\n",
        "    monet_ds = monet_ds.repeat()\n",
        "    monet_ds = monet_ds.shuffle(2048)    \n",
        "    monet_ds = monet_ds.batch(batch_size, drop_remainder=True)\n",
        "    monet_ds = monet_ds.cache()\n",
        "    monet_ds = monet_ds.prefetch(AUTO)\n",
        "    \n",
        "    photo_ds = photo_ds.map(augment, num_parallel_calls=AUTO)\n",
        "    photo_ds = photo_ds.repeat()\n",
        "    photo_ds = photo_ds.shuffle(2048)    \n",
        "    photo_ds = photo_ds.batch(batch_size, drop_remainder=True)\n",
        "    photo_ds = photo_ds.cache()\n",
        "    photo_ds = photo_ds.prefetch(AUTO)\n",
        "    \n",
        "    gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
        "    \n",
        "    return gan_ds"
      ],
      "metadata": {
        "id": "odQ0-3ZUpF3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_generated(b, gen, num_of_samples):\n",
        "    b_iter = iter(b)\n",
        "    for n_sample in range(num_of_samples):\n",
        "        example_sample = next(b_iter)\n",
        "        generated_sample = gen.predict(example_sample)\n",
        "        \n",
        "        plt.subplot(121)\n",
        "        plt.title(\"Input image\")\n",
        "        plt.imshow(example_sample[0] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(122)\n",
        "        plt.title(\"Generated image\")\n",
        "        plt.imshow(generated_sample[0] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "def gen_pred_and_save(input_b, gen, output_path):\n",
        "    i = 1 # for status\n",
        "    for img in input_b:\n",
        "        prediction = gen(img, training=False)[0].numpy()\n",
        "        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
        "        im = PIL.Image.fromarray(prediction)\n",
        "        im.save(f'{output_path}{str(i)}.jpg')\n",
        "        i += 1\n",
        "        if i%50==0:\n",
        "            print(i)\n",
        "            print(round(i/7038,2))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:38:05.936233Z",
          "iopub.execute_input": "2022-08-08T10:38:05.936497Z",
          "iopub.status.idle": "2022-08-08T10:38:05.946536Z",
          "shell.execute_reply.started": "2022-08-08T10:38:05.936467Z",
          "shell.execute_reply": "2022-08-08T10:38:05.945420Z"
        },
        "trusted": true,
        "id": "OHiDHWZXpF3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = get_gan_dataset(MONET_FILENAMES, PHOTO_FILENAMES, augment=data_augment, repeat=True, shuffle=True, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:08.815938Z",
          "iopub.execute_input": "2022-08-08T10:34:08.816139Z",
          "iopub.status.idle": "2022-08-08T10:34:09.772088Z",
          "shell.execute_reply.started": "2022-08-08T10:34:08.816116Z",
          "shell.execute_reply": "2022-08-08T10:34:09.771236Z"
        },
        "trusted": true,
        "id": "2mXgPoEmpF3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_monet , example_photo = next(iter(full_dataset))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:09.773367Z",
          "iopub.execute_input": "2022-08-08T10:34:09.773620Z",
          "iopub.status.idle": "2022-08-08T10:34:15.381811Z",
          "shell.execute_reply.started": "2022-08-08T10:34:09.773592Z",
          "shell.execute_reply": "2022-08-08T10:34:15.380353Z"
        },
        "trusted": true,
        "id": "kN14y84dpF3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data exapmles after augmentions"
      ],
      "metadata": {
        "id": "8MgnuXtvpF3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Photo')\n",
        "plt.imshow(example_photo[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Monet')\n",
        "plt.imshow(example_monet[0] * 0.5 + 0.5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:15.383198Z",
          "iopub.execute_input": "2022-08-08T10:34:15.383460Z",
          "iopub.status.idle": "2022-08-08T10:34:16.081272Z",
          "shell.execute_reply.started": "2022-08-08T10:34:15.383430Z",
          "shell.execute_reply": "2022-08-08T10:34:16.080437Z"
        },
        "trusted": true,
        "id": "WIhhyD6RpF3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we define the model. starting with the Generator, and Discriminator. then for the complete model."
      ],
      "metadata": {
        "id": "xlAc5B3YpF3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**U-net defenition**\n",
        "\n",
        "define encoder layer, note that the dimensions for the conv layer are adjustable, for better performance tuning and easy model manipulations. as same for the Decoder layer"
      ],
      "metadata": {
        "id": "cb4QfdGkpF3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EncoderLayer(filters, size, apply_instancenorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    result.add(layers.LeakyReLU())\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:16.082966Z",
          "iopub.execute_input": "2022-08-08T10:34:16.083275Z",
          "iopub.status.idle": "2022-08-08T10:34:16.091376Z",
          "shell.execute_reply.started": "2022-08-08T10:34:16.083239Z",
          "shell.execute_reply": "2022-08-08T10:34:16.090474Z"
        },
        "trusted": true,
        "id": "wNw-QBpvpF3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define decoder layer"
      ],
      "metadata": {
        "id": "Jk1MTGXHpF3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DecoderLayer(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=False))\n",
        "\n",
        "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(layers.Dropout(0.5))\n",
        "\n",
        "    result.add(layers.ReLU())\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:16.095477Z",
          "iopub.execute_input": "2022-08-08T10:34:16.095769Z",
          "iopub.status.idle": "2022-08-08T10:34:16.102904Z",
          "shell.execute_reply.started": "2022-08-08T10:34:16.095717Z",
          "shell.execute_reply": "2022-08-08T10:34:16.101840Z"
        },
        "trusted": true,
        "id": "63Oxu-kvpF3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator**\n",
        "\n",
        "using the layers we defined, we build the Generator. not that it us a U-net. the skip connections defined at the bottem and the model is plotted after wards"
      ],
      "metadata": {
        "id": "6xWnE9NspF3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator():\n",
        "    inputs = layers.Input(shape=[256,256,3])\n",
        "\n",
        "    # bs = batch size\n",
        "    Encoder = [\n",
        "        EncoderLayer(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n",
        "        EncoderLayer(128, 4), # (bs, 64, 64, 128)\n",
        "        EncoderLayer(256, 4), # (bs, 32, 32, 256)\n",
        "        EncoderLayer(512, 4), # (bs, 16, 16, 512)\n",
        "        EncoderLayer(512, 4), # (bs, 8, 8, 512)\n",
        "        EncoderLayer(512, 4), # (bs, 4, 4, 512)\n",
        "        EncoderLayer(512, 4), # (bs, 2, 2, 512)\n",
        "        EncoderLayer(512, 4), # (bs, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    Decoder = [\n",
        "        DecoderLayer(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
        "        DecoderLayer(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
        "        DecoderLayer(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
        "        DecoderLayer(512, 4), # (bs, 16, 16, 1024)\n",
        "        DecoderLayer(256, 4), # (bs, 32, 32, 512)\n",
        "        DecoderLayer(128, 4), # (bs, 64, 64, 256)\n",
        "        DecoderLayer(64, 4), # (bs, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                  strides=2,\n",
        "                                  padding='same',\n",
        "                                  kernel_initializer=initializer,\n",
        "                                  activation='tanh') # (bs, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in Encoder:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and adding the skip connections\n",
        "    for up, skip in zip(Decoder, skips):\n",
        "        x = up(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "tf.keras.utils.plot_model(Generator())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:16.104720Z",
          "iopub.execute_input": "2022-08-08T10:34:16.105158Z",
          "iopub.status.idle": "2022-08-08T10:34:19.137241Z",
          "shell.execute_reply.started": "2022-08-08T10:34:16.105118Z",
          "shell.execute_reply": "2022-08-08T10:34:19.136174Z"
        },
        "trusted": true,
        "id": "FewA80erpF3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discrimonator**"
      ],
      "metadata": {
        "id": "VANpb5xppF3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "\n",
        "    x = inp\n",
        "\n",
        "    down1 = EncoderLayer(64, 4, False)(x) # (bs, 128, 128, 64)\n",
        "    down2 = EncoderLayer(128, 4)(down1) # (bs, 64, 64, 128)\n",
        "    down3 = EncoderLayer(256, 4)(down2) # (bs, 32, 32, 256)\n",
        "\n",
        "    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "\n",
        "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
        "\n",
        "    leaky_relu = layers.LeakyReLU()(norm1)\n",
        "\n",
        "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "\n",
        "    last = layers.Conv2D(1, 4, strides=1,kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)\n",
        "\n",
        "tf.keras.utils.plot_model(Discriminator())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:19.139100Z",
          "iopub.execute_input": "2022-08-08T10:34:19.139536Z",
          "iopub.status.idle": "2022-08-08T10:34:19.524845Z",
          "shell.execute_reply.started": "2022-08-08T10:34:19.139494Z",
          "shell.execute_reply": "2022-08-08T10:34:19.523852Z"
        },
        "trusted": true,
        "id": "OQ47rRsYpF3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    monet_generator = Generator() # photos to Monet paintings\n",
        "    photo_generator = Generator() # Monet paintings to photos\n",
        "\n",
        "    monet_discriminator = Discriminator() # Monet paintings and generated paintings\n",
        "    photo_discriminator = Discriminator() # real photos and generated photos"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:19.526709Z",
          "iopub.execute_input": "2022-08-08T10:34:19.528042Z",
          "iopub.status.idle": "2022-08-08T10:34:28.780483Z",
          "shell.execute_reply.started": "2022-08-08T10:34:19.528003Z",
          "shell.execute_reply": "2022-08-08T10:34:28.779835Z"
        },
        "trusted": true,
        "id": "zk1O_o-HpF3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model build**"
      ],
      "metadata": {
        "id": "2ZZ7g1CPpF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGan(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_generator,\n",
        "        photo_generator,\n",
        "        monet_discriminator,\n",
        "        photo_discriminator,\n",
        "        lambda_cycle=10,\n",
        "    ):\n",
        "        super(CycleGan, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        \n",
        "    def compile(\n",
        "        self,\n",
        "        m_gen_optimizer,\n",
        "        p_gen_optimizer,\n",
        "        m_disc_optimizer,\n",
        "        p_disc_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "        cycle_loss_fn,\n",
        "        identity_loss_fn\n",
        "    ):\n",
        "        super(CycleGan, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "        \n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # photo to monet\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "            # monet to photo\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "            # generating itself\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # discriminator real images\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "            # discriminator fake images\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "            \n",
        "            # Losses\n",
        "            # generator loss\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "            # total cycle consistency loss\n",
        "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
        "            # total generator loss\n",
        "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
        "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
        "            # evaluates discriminator loss\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # gradients for generator and discriminator\n",
        "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
        "                                                  self.m_gen.trainable_variables)\n",
        "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
        "                                                  self.p_gen.trainable_variables)\n",
        "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
        "                                                      self.m_disc.trainable_variables)\n",
        "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
        "                                                      self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply gradients - optimizer\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
        "                                                 self.m_gen.trainable_variables))\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
        "                                                 self.p_gen.trainable_variables))\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
        "                                                  self.m_disc.trainable_variables))\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
        "                                                  self.p_disc.trainable_variables))\n",
        "        return {\n",
        "            \"monet_gen_loss\": total_monet_gen_loss,\n",
        "            \"photo_gen_loss\": total_photo_gen_loss,\n",
        "            \"monet_disc_loss\": monet_disc_loss,\n",
        "            \"photo_disc_loss\": photo_disc_loss,\n",
        "            \"cycle_loss\":  total_cycle_loss\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.782120Z",
          "iopub.execute_input": "2022-08-08T10:34:28.782601Z",
          "iopub.status.idle": "2022-08-08T10:34:28.800656Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.782560Z",
          "shell.execute_reply": "2022-08-08T10:34:28.799879Z"
        },
        "trusted": true,
        "id": "yd6wTqdKpF3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss function defenitions**"
      ],
      "metadata": {
        "id": "id3A7OSYpF3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    def discriminator_loss(real, generated):\n",
        "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
        "        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
        "        total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "        return total_disc_loss * 0.5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.802031Z",
          "iopub.execute_input": "2022-08-08T10:34:28.802265Z",
          "iopub.status.idle": "2022-08-08T10:34:28.826432Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.802239Z",
          "shell.execute_reply": "2022-08-08T10:34:28.825566Z"
        },
        "trusted": true,
        "id": "eeZdCnd4pF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    def generator_loss(generated):\n",
        "        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.827604Z",
          "iopub.execute_input": "2022-08-08T10:34:28.827860Z",
          "iopub.status.idle": "2022-08-08T10:34:28.839646Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.827831Z",
          "shell.execute_reply": "2022-08-08T10:34:28.838810Z"
        },
        "trusted": true,
        "id": "AaTcn8KHpF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "        return LAMBDA * loss1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.840835Z",
          "iopub.execute_input": "2022-08-08T10:34:28.841095Z",
          "iopub.status.idle": "2022-08-08T10:34:28.852827Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.841058Z",
          "shell.execute_reply": "2022-08-08T10:34:28.852021Z"
        },
        "trusted": true,
        "id": "QM3PtUz2pF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    def identity_loss(real_image, same_image, LAMBDA):\n",
        "        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "        return LAMBDA * 0.5 * loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.854020Z",
          "iopub.execute_input": "2022-08-08T10:34:28.854421Z",
          "iopub.status.idle": "2022-08-08T10:34:28.864727Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.854394Z",
          "shell.execute_reply": "2022-08-08T10:34:28.863766Z"
        },
        "trusted": true,
        "id": "so5rdyaApF3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.867541Z",
          "iopub.execute_input": "2022-08-08T10:34:28.867997Z",
          "iopub.status.idle": "2022-08-08T10:34:28.876616Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.867968Z",
          "shell.execute_reply": "2022-08-08T10:34:28.875884Z"
        },
        "trusted": true,
        "id": "_4dZeOsxpF3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    cycle_gan_model = CycleGan(\n",
        "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
        "    )\n",
        "\n",
        "    cycle_gan_model.compile(\n",
        "        m_gen_optimizer = monet_generator_optimizer,\n",
        "        p_gen_optimizer = photo_generator_optimizer,\n",
        "        m_disc_optimizer = monet_discriminator_optimizer,\n",
        "        p_disc_optimizer = photo_discriminator_optimizer,\n",
        "        gen_loss_fn = generator_loss,\n",
        "        disc_loss_fn = discriminator_loss,\n",
        "        cycle_loss_fn = calc_cycle_loss,\n",
        "        identity_loss_fn = identity_loss\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.877838Z",
          "iopub.execute_input": "2022-08-08T10:34:28.878050Z",
          "iopub.status.idle": "2022-08-08T10:34:28.944097Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.878026Z",
          "shell.execute_reply": "2022-08-08T10:34:28.943372Z"
        },
        "trusted": true,
        "id": "G_yufRJzpF3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "MXvaEAYTpF3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cycle_gan_model.fit(\n",
        "                                full_dataset,\n",
        "                                epochs=EPOCHS_NUM,\n",
        "                                steps_per_epoch=(max(n_monet_samples, n_photo_samples)//BATCH_SIZE),\n",
        "                            )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:34:28.945322Z",
          "iopub.execute_input": "2022-08-08T10:34:28.945708Z",
          "iopub.status.idle": "2022-08-08T10:38:04.269945Z",
          "shell.execute_reply.started": "2022-08-08T10:34:28.945667Z",
          "shell.execute_reply": "2022-08-08T10:38:04.268943Z"
        },
        "trusted": true,
        "id": "yNSpZp6HpF3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model evaluation**"
      ],
      "metadata": {
        "id": "SyZwgKuDpF3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot the loss graph for each of the 4 models, monet Generetor monet Discriminator, photo Generetor, photo Discriminator and cycle loss."
      ],
      "metadata": {
        "id": "0ApKKBZvpF3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monet_gen_loss = []\n",
        "photo_gen_loss = []\n",
        "monet_disc_loss = []\n",
        "photo_disc_loss = []\n",
        "total_cycle_loss = []\n",
        "\n",
        "print(history.history.keys())\n",
        "for epoc in range(EPOCHS_NUM):\n",
        "    #print(history.history['monet_gen_loss'][epoc].shape)\n",
        "    monet_gen_loss.append(np.average(history.history['monet_gen_loss'][epoc].flatten()))    \n",
        "    photo_gen_loss.append(np.average(history.history['photo_gen_loss'][epoc].flatten()))\n",
        "    monet_disc_loss.append(np.average(history.history['monet_disc_loss'][epoc].flatten()))\n",
        "    photo_disc_loss.append(np.average(history.history['photo_disc_loss'][epoc].flatten()))\n",
        "    total_cycle_loss.append(np.average(history.history['cycle_loss'][epoc]))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:38:04.271748Z",
          "iopub.execute_input": "2022-08-08T10:38:04.272740Z",
          "iopub.status.idle": "2022-08-08T10:38:05.934870Z",
          "shell.execute_reply.started": "2022-08-08T10:38:04.272674Z",
          "shell.execute_reply": "2022-08-08T10:38:05.933890Z"
        },
        "trusted": true,
        "id": "YcmyKewHpF3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_generated(load_dataset(PHOTO_FILENAMES).batch(1), monet_generator, 20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:38:05.947796Z",
          "iopub.execute_input": "2022-08-08T10:38:05.948049Z",
          "iopub.status.idle": "2022-08-08T10:38:25.785030Z",
          "shell.execute_reply.started": "2022-08-08T10:38:05.948021Z",
          "shell.execute_reply": "2022-08-08T10:38:25.784172Z"
        },
        "trusted": true,
        "id": "G6DmJjdEpF3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create output"
      ],
      "metadata": {
        "id": "dCbTBRTwpF3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('../images/') # Create folder to save generated images\n",
        "gen_pred_and_save(load_dataset(PHOTO_FILENAMES).batch(1), monet_generator, '../images/')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:38:25.786190Z",
          "iopub.execute_input": "2022-08-08T10:38:25.786417Z",
          "iopub.status.idle": "2022-08-08T10:38:46.801739Z",
          "shell.execute_reply.started": "2022-08-08T10:38:25.786391Z",
          "shell.execute_reply": "2022-08-08T10:38:46.799986Z"
        },
        "trusted": true,
        "id": "2pGaxeslpF3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zip output files"
      ],
      "metadata": {
        "id": "9qRumLVmpF3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/kaggle/working/images/', 'zip', '../images')\n",
        "\n",
        "print(\"Generated samples: {s}\".format(s=len([name for name in os.listdir('../images/') if os.path.isfile(os.path.join('../images/', name))])))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-08T10:38:55.631553Z",
          "iopub.execute_input": "2022-08-08T10:38:55.631883Z",
          "iopub.status.idle": "2022-08-08T10:38:55.638740Z",
          "shell.execute_reply.started": "2022-08-08T10:38:55.631849Z",
          "shell.execute_reply": "2022-08-08T10:38:55.637941Z"
        },
        "trusted": true,
        "id": "onbCtVh0pF3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}